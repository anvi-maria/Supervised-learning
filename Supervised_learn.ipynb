{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c19d25db-b5e4-4a23-9aa6-aec3344821a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.5.2-cp312-cp312-win_amd64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\anvim\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (2.0.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\anvim\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn) (1.14.1)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.5.2-cp312-cp312-win_amd64.whl (11.0 MB)\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/11.0 MB 2.2 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 0.3/11.0 MB 4.2 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 0.4/11.0 MB 3.4 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 0.7/11.0 MB 3.9 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 1.0/11.0 MB 4.7 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 1.2/11.0 MB 4.7 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 1.4/11.0 MB 4.8 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 1.7/11.0 MB 4.7 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 2.0/11.0 MB 4.8 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 2.3/11.0 MB 5.0 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 2.6/11.0 MB 5.2 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.9/11.0 MB 5.4 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 3.5/11.0 MB 5.6 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 3.9/11.0 MB 5.7 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 4.2/11.0 MB 5.8 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 4.6/11.0 MB 5.9 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 4.9/11.0 MB 6.0 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 5.3/11.0 MB 6.1 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 5.6/11.0 MB 6.1 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 5.8/11.0 MB 6.1 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 5.8/11.0 MB 6.1 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 6.4/11.0 MB 6.2 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 6.7/11.0 MB 6.1 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 7.1/11.0 MB 6.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 7.4/11.0 MB 6.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 7.7/11.0 MB 6.3 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 8.0/11.0 MB 6.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 8.2/11.0 MB 6.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 8.5/11.0 MB 6.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 8.7/11.0 MB 6.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 9.2/11.0 MB 6.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 9.5/11.0 MB 6.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 9.9/11.0 MB 6.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.3/11.0 MB 6.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.7/11.0 MB 6.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.0/11.0 MB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.0/11.0 MB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.0/11.0 MB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.0/11.0 MB 6.1 MB/s eta 0:00:00\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "   ---------------------------------------- 0.0/301.8 kB ? eta -:--:--\n",
      "   ------------------------- -------------- 194.6/301.8 kB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 301.8/301.8 kB 3.1 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.5.2 threadpoolctl-3.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78095e08-b08c-4e54-a8fb-6ef7719b735e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
      "0        17.99         10.38          122.80     1001.0          0.11840   \n",
      "1        20.57         17.77          132.90     1326.0          0.08474   \n",
      "2        19.69         21.25          130.00     1203.0          0.10960   \n",
      "3        11.42         20.38           77.58      386.1          0.14250   \n",
      "4        20.29         14.34          135.10     1297.0          0.10030   \n",
      "\n",
      "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
      "0           0.27760          0.3001              0.14710         0.2419   \n",
      "1           0.07864          0.0869              0.07017         0.1812   \n",
      "2           0.15990          0.1974              0.12790         0.2069   \n",
      "3           0.28390          0.2414              0.10520         0.2597   \n",
      "4           0.13280          0.1980              0.10430         0.1809   \n",
      "\n",
      "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
      "0                 0.07871  ...          17.33           184.60      2019.0   \n",
      "1                 0.05667  ...          23.41           158.80      1956.0   \n",
      "2                 0.05999  ...          25.53           152.50      1709.0   \n",
      "3                 0.09744  ...          26.50            98.87       567.7   \n",
      "4                 0.05883  ...          16.67           152.20      1575.0   \n",
      "\n",
      "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
      "0            0.1622             0.6656           0.7119                0.2654   \n",
      "1            0.1238             0.1866           0.2416                0.1860   \n",
      "2            0.1444             0.4245           0.4504                0.2430   \n",
      "3            0.2098             0.8663           0.6869                0.2575   \n",
      "4            0.1374             0.2050           0.4000                0.1625   \n",
      "\n",
      "   worst symmetry  worst fractal dimension  target  \n",
      "0          0.4601                  0.11890       0  \n",
      "1          0.2750                  0.08902       0  \n",
      "2          0.3613                  0.08758       0  \n",
      "3          0.6638                  0.17300       0  \n",
      "4          0.2364                  0.07678       0  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# Load the dataset\n",
    "cancer_data = load_breast_cancer()\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(data=cancer_data.data, columns=cancer_data.feature_names)\n",
    "\n",
    "# Add the target column to the DataFrame\n",
    "df['target'] = cancer_data.target\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f14084f-bdee-487c-a9b7-854ba9dc420a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in the dataset:\n",
      " mean radius                0\n",
      "mean texture               0\n",
      "mean perimeter             0\n",
      "mean area                  0\n",
      "mean smoothness            0\n",
      "mean compactness           0\n",
      "mean concavity             0\n",
      "mean concave points        0\n",
      "mean symmetry              0\n",
      "mean fractal dimension     0\n",
      "radius error               0\n",
      "texture error              0\n",
      "perimeter error            0\n",
      "area error                 0\n",
      "smoothness error           0\n",
      "compactness error          0\n",
      "concavity error            0\n",
      "concave points error       0\n",
      "symmetry error             0\n",
      "fractal dimension error    0\n",
      "worst radius               0\n",
      "worst texture              0\n",
      "worst perimeter            0\n",
      "worst area                 0\n",
      "worst smoothness           0\n",
      "worst compactness          0\n",
      "worst concavity            0\n",
      "worst concave points       0\n",
      "worst symmetry             0\n",
      "worst fractal dimension    0\n",
      "target                     0\n",
      "dtype: int64\n",
      "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
      "0     1.097064     -2.073335        1.269934   0.984375         1.568466   \n",
      "1     1.829821     -0.353632        1.685955   1.908708        -0.826962   \n",
      "2     1.579888      0.456187        1.566503   1.558884         0.942210   \n",
      "3    -0.768909      0.253732       -0.592687  -0.764464         3.283553   \n",
      "4     1.750297     -1.151816        1.776573   1.826229         0.280372   \n",
      "\n",
      "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
      "0          3.283515        2.652874             2.532475       2.217515   \n",
      "1         -0.487072       -0.023846             0.548144       0.001392   \n",
      "2          1.052926        1.363478             2.037231       0.939685   \n",
      "3          3.402909        1.915897             1.451707       2.867383   \n",
      "4          0.539340        1.371011             1.428493      -0.009560   \n",
      "\n",
      "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
      "0                2.255747  ...      -1.359293         2.303601    2.001237   \n",
      "1               -0.868652  ...      -0.369203         1.535126    1.890489   \n",
      "2               -0.398008  ...      -0.023974         1.347475    1.456285   \n",
      "3                4.910919  ...       0.133984        -0.249939   -0.550021   \n",
      "4               -0.562450  ...      -1.466770         1.338539    1.220724   \n",
      "\n",
      "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
      "0          1.307686           2.616665         2.109526              2.296076   \n",
      "1         -0.375612          -0.430444        -0.146749              1.087084   \n",
      "2          0.527407           1.082932         0.854974              1.955000   \n",
      "3          3.394275           3.893397         1.989588              2.175786   \n",
      "4          0.220556          -0.313395         0.613179              0.729259   \n",
      "\n",
      "   worst symmetry  worst fractal dimension  target  \n",
      "0        2.750622                 1.937015       0  \n",
      "1       -0.243890                 0.281190       0  \n",
      "2        1.152255                 0.201391       0  \n",
      "3        6.046041                 4.935010       0  \n",
      "4       -0.868353                -0.397100       0  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler  # Import StandardScaler\n",
    "print(\"Missing values in the dataset:\\n\", df.isnull().sum())\n",
    "\n",
    "# If there were missing values, you could handle them as needed:\n",
    "# df.fillna(df.mean(), inplace=True)  # Example: Replace missing values with the mean\n",
    "\n",
    "# Step 2: Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(df.drop('target', axis=1))\n",
    "\n",
    "# Convert the scaled features back to a DataFrame\n",
    "df_scaled = pd.DataFrame(scaled_features, columns=cancer_data.feature_names)\n",
    "\n",
    "# Add the target column back to the scaled DataFrame\n",
    "df_scaled['target'] = df['target']\n",
    "\n",
    "# Display the first few rows of the scaled DataFrame\n",
    "print(df_scaled.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f049990-4a68-4a83-b5a6-1c3f45b49bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression: 97.37%\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96        43\n",
      "           1       0.97      0.99      0.98        71\n",
      "\n",
      "    accuracy                           0.97       114\n",
      "   macro avg       0.97      0.97      0.97       114\n",
      "weighted avg       0.97      0.97      0.97       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Split the dataset into features and target variable\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "\n",
    "# Step 1: Preprocess the data (Feature Scaling)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Step 2: Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Implement Logistic Regression\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Step 4: Make predictions and evaluate the model\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "# Calculate accuracy and print the classification report\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy of Logistic Regression: {accuracy * 100:.2f}%\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d327b682-1ead-4ddc-9773-50a06a82da43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier Accuracy: 94.74%\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93        43\n",
      "           1       0.96      0.96      0.96        71\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.94      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize and train the model\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_dt = dt_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "print(f\"Decision Tree Classifier Accuracy: {accuracy_dt * 100:.2f}%\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67c07fc9-3075-466a-8da3-64f15cac3edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Accuracy: 96.49%\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.93      0.95        43\n",
      "           1       0.96      0.99      0.97        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.97      0.96      0.96       114\n",
      "weighted avg       0.97      0.96      0.96       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize and train the model\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_rf = rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "print(f\"Random Forest Classifier Accuracy: {accuracy_rf * 100:.2f}%\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "600961aa-a7c7-4c6d-a38a-2eec20e5c564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classifier Accuracy: 95.61%\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94        43\n",
      "           1       0.97      0.96      0.96        71\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.95      0.96      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Initialize and train the model\n",
    "svm_classifier = SVC(kernel='linear', random_state=42)\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_svm = svm_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "print(f\"SVM Classifier Accuracy: {accuracy_svm * 100:.2f}%\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e78d7f7c-14a3-4c57-909a-17fa73988007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-NN Classifier Accuracy: 94.74%\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93        43\n",
      "           1       0.96      0.96      0.96        71\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.94      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Initialize and train the model\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_knn = knn_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
    "print(f\"k-NN Classifier Accuracy: {accuracy_knn * 100:.2f}%\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0815e125-78cb-4ac8-9932-12b03512d901",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best-Performing Algorithm: Random Forest Classifier typically performs the best in terms of accuracy and generalization on the breast cancer dataset. \n",
    "# It reduces overfitting compared to Decision Trees and can handle non-linearity and complex feature interactions.\n",
    "\n",
    "#Worst-Performing Algorithm: Decision Tree Classifier often performs the worst due to its tendency to overfit, especially without parameter tuning \n",
    "#or pruning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc365aa-adf1-4424-a906-04f3053844a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
